{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Duration', 'Source Port', 'Destination Port', 'Protocol', 'Flags',\n",
      "       'Packets', 'Bytes', 'Mean Payload Size', 'Std Payload Size',\n",
      "       'Min Payload Size', 'Max Payload Size', 'Mean Entropy', 'Min Entropy',\n",
      "       'Max Entropy', 'Mean Inter-Packet Interval',\n",
      "       'Min Inter-Packet Interval', 'Max Inter-Packet Interval',\n",
      "       'Bytes per Packet', 'Packets per Second', 'Bytes per Second',\n",
      "       'Destination Common Port Usage', 'Flags Count', 'SYN Count',\n",
      "       'ACK Count', 'FIN Count', 'Is HTTP', 'Is Internal IP', 'Direction',\n",
      "       'Short Duration', 'Single Packet'],\n",
      "      dtype='object')\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Index(['Duration', 'Source Port', 'Destination Port', 'Protocol', 'Flags',\n",
      "       'Packets', 'Bytes', 'Mean Payload Size', 'Std Payload Size',\n",
      "       'Min Payload Size', 'Max Payload Size', 'Mean Entropy', 'Min Entropy',\n",
      "       'Max Entropy', 'Mean Inter-Packet Interval',\n",
      "       'Min Inter-Packet Interval', 'Max Inter-Packet Interval',\n",
      "       'Bytes per Packet', 'Packets per Second', 'Bytes per Second',\n",
      "       'Destination Common Port Usage', 'Flags Count', 'SYN Count',\n",
      "       'ACK Count', 'FIN Count', 'Is HTTP', 'Is Internal IP', 'Direction',\n",
      "       'Short Duration', 'Single Packet'],\n",
      "      dtype='object')\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Index(['Duration', 'Source Port', 'Destination Port', 'Protocol', 'Flags',\n",
      "       'Packets', 'Bytes', 'Mean Payload Size', 'Std Payload Size',\n",
      "       'Min Payload Size', 'Max Payload Size', 'Mean Entropy', 'Min Entropy',\n",
      "       'Max Entropy', 'Mean Inter-Packet Interval',\n",
      "       'Min Inter-Packet Interval', 'Max Inter-Packet Interval',\n",
      "       'Bytes per Packet', 'Packets per Second', 'Bytes per Second',\n",
      "       'Destination Common Port Usage', 'Flags Count', 'SYN Count',\n",
      "       'ACK Count', 'FIN Count', 'Is HTTP', 'Is Internal IP', 'Direction',\n",
      "       'Short Duration', 'Single Packet'],\n",
      "      dtype='object')\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Index(['Duration', 'Source Port', 'Destination Port', 'Protocol', 'Flags',\n",
      "       'Packets', 'Bytes', 'Mean Payload Size', 'Std Payload Size',\n",
      "       'Min Payload Size', 'Max Payload Size', 'Mean Entropy', 'Min Entropy',\n",
      "       'Max Entropy', 'Mean Inter-Packet Interval',\n",
      "       'Min Inter-Packet Interval', 'Max Inter-Packet Interval',\n",
      "       'Bytes per Packet', 'Packets per Second', 'Bytes per Second',\n",
      "       'Destination Common Port Usage', 'Flags Count', 'SYN Count',\n",
      "       'ACK Count', 'FIN Count', 'Is HTTP', 'Is Internal IP', 'Direction',\n",
      "       'Short Duration', 'Single Packet'],\n",
      "      dtype='object')\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Index(['Duration', 'Source Port', 'Destination Port', 'Protocol', 'Flags',\n",
      "       'Packets', 'Bytes', 'Mean Payload Size', 'Std Payload Size',\n",
      "       'Min Payload Size', 'Max Payload Size', 'Mean Entropy', 'Min Entropy',\n",
      "       'Max Entropy', 'Mean Inter-Packet Interval',\n",
      "       'Min Inter-Packet Interval', 'Max Inter-Packet Interval',\n",
      "       'Bytes per Packet', 'Packets per Second', 'Bytes per Second',\n",
      "       'Destination Common Port Usage', 'Flags Count', 'SYN Count',\n",
      "       'ACK Count', 'FIN Count', 'Is HTTP', 'Is Internal IP', 'Direction',\n",
      "       'Short Duration', 'Single Packet'],\n",
      "      dtype='object')\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Index(['Duration', 'Source Port', 'Destination Port', 'Protocol', 'Flags',\n",
      "       'Packets', 'Bytes', 'Mean Payload Size', 'Std Payload Size',\n",
      "       'Min Payload Size', 'Max Payload Size', 'Mean Entropy', 'Min Entropy',\n",
      "       'Max Entropy', 'Mean Inter-Packet Interval',\n",
      "       'Min Inter-Packet Interval', 'Max Inter-Packet Interval',\n",
      "       'Bytes per Packet', 'Packets per Second', 'Bytes per Second',\n",
      "       'Destination Common Port Usage', 'Flags Count', 'SYN Count',\n",
      "       'ACK Count', 'FIN Count', 'Is HTTP', 'Is Internal IP', 'Direction',\n",
      "       'Short Duration', 'Single Packet'],\n",
      "      dtype='object')\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Index(['Duration', 'Source Port', 'Destination Port', 'Protocol', 'Flags',\n",
      "       'Packets', 'Bytes', 'Mean Payload Size', 'Std Payload Size',\n",
      "       'Min Payload Size', 'Max Payload Size', 'Mean Entropy', 'Min Entropy',\n",
      "       'Max Entropy', 'Mean Inter-Packet Interval',\n",
      "       'Min Inter-Packet Interval', 'Max Inter-Packet Interval',\n",
      "       'Bytes per Packet', 'Packets per Second', 'Bytes per Second',\n",
      "       'Destination Common Port Usage', 'Flags Count', 'SYN Count',\n",
      "       'ACK Count', 'FIN Count', 'Is HTTP', 'Is Internal IP', 'Direction',\n",
      "       'Short Duration', 'Single Packet'],\n",
      "      dtype='object')\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Index(['Duration', 'Source Port', 'Destination Port', 'Protocol', 'Flags',\n",
      "       'Packets', 'Bytes', 'Mean Payload Size', 'Std Payload Size',\n",
      "       'Min Payload Size', 'Max Payload Size', 'Mean Entropy', 'Min Entropy',\n",
      "       'Max Entropy', 'Mean Inter-Packet Interval',\n",
      "       'Min Inter-Packet Interval', 'Max Inter-Packet Interval',\n",
      "       'Bytes per Packet', 'Packets per Second', 'Bytes per Second',\n",
      "       'Destination Common Port Usage', 'Flags Count', 'SYN Count',\n",
      "       'ACK Count', 'FIN Count', 'Is HTTP', 'Is Internal IP', 'Direction',\n",
      "       'Short Duration', 'Single Packet'],\n",
      "      dtype='object')\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Index(['Duration', 'Source Port', 'Destination Port', 'Protocol', 'Flags',\n",
      "       'Packets', 'Bytes', 'Mean Payload Size', 'Std Payload Size',\n",
      "       'Min Payload Size', 'Max Payload Size', 'Mean Entropy', 'Min Entropy',\n",
      "       'Max Entropy', 'Mean Inter-Packet Interval',\n",
      "       'Min Inter-Packet Interval', 'Max Inter-Packet Interval',\n",
      "       'Bytes per Packet', 'Packets per Second', 'Bytes per Second',\n",
      "       'Destination Common Port Usage', 'Flags Count', 'SYN Count',\n",
      "       'ACK Count', 'FIN Count', 'Is HTTP', 'Is Internal IP', 'Direction',\n",
      "       'Short Duration', 'Single Packet'],\n",
      "      dtype='object')\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Index(['Duration', 'Source Port', 'Destination Port', 'Protocol', 'Flags',\n",
      "       'Packets', 'Bytes', 'Mean Payload Size', 'Std Payload Size',\n",
      "       'Min Payload Size', 'Max Payload Size', 'Mean Entropy', 'Min Entropy',\n",
      "       'Max Entropy', 'Mean Inter-Packet Interval',\n",
      "       'Min Inter-Packet Interval', 'Max Inter-Packet Interval',\n",
      "       'Bytes per Packet', 'Packets per Second', 'Bytes per Second',\n",
      "       'Destination Common Port Usage', 'Flags Count', 'SYN Count',\n",
      "       'ACK Count', 'FIN Count', 'Is HTTP', 'Is Internal IP', 'Direction',\n",
      "       'Short Duration', 'Single Packet'],\n",
      "      dtype='object')\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "                                                File  Benign_Count  \\\n",
      "0  ../../data/collected/normal_machines/benign_3.csv           434   \n",
      "1  ../../data/collected/normal_machines/benign_2.csv           504   \n",
      "2  ../../data/collected/normal_machines/benign_5.csv           435   \n",
      "3  ../../data/collected/normal_machines/benign_4.csv           521   \n",
      "4  ../../data/collected/normal_machines/benign_1.csv           411   \n",
      "5  ../../data/collected/infected_machines/infecte...           529   \n",
      "6  ../../data/collected/infected_machines/infecte...           417   \n",
      "7  ../../data/collected/infected_machines/infecte...           506   \n",
      "8  ../../data/collected/infected_machines/infecte...           462   \n",
      "9  ../../data/collected/infected_machines/infecte...           535   \n",
      "\n",
      "   Dridex_Count Final_Classification  \n",
      "0             0               Benign  \n",
      "1             0               Benign  \n",
      "2             0               Benign  \n",
      "3             0               Benign  \n",
      "4             0               Benign  \n",
      "5           143            Malicious  \n",
      "6           109            Malicious  \n",
      "7           142            Malicious  \n",
      "8           130            Malicious  \n",
      "9           155            Malicious  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load saved LSTM model (ensure the model was saved using model.save(\"LSTM_model.h5\"))\n",
    "model = tf.keras.models.load_model(\"../../models/dridex/LSTM.h5\")\n",
    "\n",
    "# Load encoders and scaler\n",
    "with open(\"../../variables/dridex/Protocol_Encoder.pkl\", \"rb\") as f:\n",
    "    protocol_encoder = pickle.load(f)\n",
    "\n",
    "with open(\"../../variables/dridex/Flags_Encoder.pkl\", \"rb\") as f:\n",
    "    flags_encoder = pickle.load(f)\n",
    "\n",
    "with open(\"../../variables/dridex/Direction_Encoder.pkl\", \"rb\") as f:\n",
    "    direction_encoder = pickle.load(f)\n",
    "\n",
    "with open(\"../../variables/dridex/scaler.pkl\", \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "# Paths to data folders\n",
    "folders = [\n",
    "    \"../../data/collected/normal_machines\",\n",
    "    \"../../data/collected/infected_machines\",\n",
    "]\n",
    "\n",
    "# Prediction threshold\n",
    "THRESHOLD = 0.5  # Since sigmoid activation is used\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "def process_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.loc[((df[\"Flags\"] == \"SYN,RST\") | (df[\"Flags\"] == \"RST,ACK\")), \"Flags\"] = (\n",
    "        \"RST\"\n",
    "    )\n",
    "    df.loc[((df[\"Protocol\"] == \"DATA-TEXT-LINES\")|(df[\"Protocol\"] == \"XML\")), \"Protocol\"] = \"MEDIA\"\n",
    "    print(df.columns)\n",
    "\n",
    "    df[\"Protocol\"] = protocol_encoder.transform(df[\"Protocol\"])\n",
    "    df[\"Flags\"] = flags_encoder.transform(df[\"Flags\"])\n",
    "    df[\"Direction\"] = direction_encoder.transform(df[\"Direction\"])\n",
    "\n",
    "    columns = df.columns\n",
    "    df = scaler.transform(df.to_numpy())\n",
    "    df = pd.DataFrame(df, columns=columns)\n",
    "\n",
    "    # Reshape for LSTM: (samples, time steps, features)\n",
    "    X_lstm = np.expand_dims(df.values, axis=1)  # Fix input shape\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_lstm)\n",
    "\n",
    "    # Convert probabilities to class labels\n",
    "    predicted_labels = (predictions > THRESHOLD).astype(int)  # 1 = Dridex, 0 = Benign\n",
    "\n",
    "    # Count\n",
    "    benign_count = np.sum(predicted_labels == 0)\n",
    "    dridex_count = np.sum(predicted_labels == 1)\n",
    "\n",
    "    # Determine file classification\n",
    "    file_status = \"Malicious\" if dridex_count > 0 else \"Benign\"\n",
    "\n",
    "    # Store results in a list\n",
    "    results.append(\n",
    "        {\n",
    "            \"File\": file_path,\n",
    "            \"Benign_Count\": benign_count,\n",
    "            \"Dridex_Count\": dridex_count,\n",
    "            \"Final_Classification\": file_status,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# Process all files in both folders\n",
    "for folder in folders:\n",
    "    for file_name in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, file_name)\n",
    "        process_file(file_path)\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save to CSV (optional)\n",
    "results_df.to_csv(\"classification_results.csv\", index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Benign_Count</th>\n",
       "      <th>Dridex_Count</th>\n",
       "      <th>Final_Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../data/collected/normal_machines/benign_3.csv</td>\n",
       "      <td>434</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../data/collected/normal_machines/benign_2.csv</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../data/collected/normal_machines/benign_5.csv</td>\n",
       "      <td>435</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../data/collected/normal_machines/benign_4.csv</td>\n",
       "      <td>521</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../data/collected/normal_machines/benign_1.csv</td>\n",
       "      <td>411</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>../../data/collected/infected_machines/infecte...</td>\n",
       "      <td>529</td>\n",
       "      <td>143</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>../../data/collected/infected_machines/infecte...</td>\n",
       "      <td>417</td>\n",
       "      <td>109</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>../../data/collected/infected_machines/infecte...</td>\n",
       "      <td>506</td>\n",
       "      <td>142</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>../../data/collected/infected_machines/infecte...</td>\n",
       "      <td>462</td>\n",
       "      <td>130</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>../../data/collected/infected_machines/infecte...</td>\n",
       "      <td>535</td>\n",
       "      <td>155</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                File  Benign_Count  \\\n",
       "0  ../../data/collected/normal_machines/benign_3.csv           434   \n",
       "1  ../../data/collected/normal_machines/benign_2.csv           504   \n",
       "2  ../../data/collected/normal_machines/benign_5.csv           435   \n",
       "3  ../../data/collected/normal_machines/benign_4.csv           521   \n",
       "4  ../../data/collected/normal_machines/benign_1.csv           411   \n",
       "5  ../../data/collected/infected_machines/infecte...           529   \n",
       "6  ../../data/collected/infected_machines/infecte...           417   \n",
       "7  ../../data/collected/infected_machines/infecte...           506   \n",
       "8  ../../data/collected/infected_machines/infecte...           462   \n",
       "9  ../../data/collected/infected_machines/infecte...           535   \n",
       "\n",
       "   Dridex_Count Final_Classification  \n",
       "0             0               Benign  \n",
       "1             0               Benign  \n",
       "2             0               Benign  \n",
       "3             0               Benign  \n",
       "4             0               Benign  \n",
       "5           143            Malicious  \n",
       "6           109            Malicious  \n",
       "7           142            Malicious  \n",
       "8           130            Malicious  \n",
       "9           155            Malicious  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yousinator/.cache/pypoetry/virtualenvs/c2-detection-TvTzD0kY-py3.10/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. LogisticRegression expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(folder):\n\u001b[1;32m     76\u001b[0m         file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder, file_name)\n\u001b[0;32m---> 77\u001b[0m         \u001b[43mprocess_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Convert results to a DataFrame\u001b[39;00m\n\u001b[1;32m     80\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n",
      "Cell \u001b[0;32mIn[64], line 54\u001b[0m, in \u001b[0;36mprocess_file\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m     52\u001b[0m X_lstm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(df\u001b[38;5;241m.\u001b[39mvalues, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_lstm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m benign_count \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(predicted_labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     57\u001b[0m dridex_count \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(predicted_labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/c2-detection-TvTzD0kY-py3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:382\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    381\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 382\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    384\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, indexing_dtype(xp))\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/c2-detection-TvTzD0kY-py3.10/lib/python3.10/site-packages/sklearn/linear_model/_base.py:363\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    360\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    361\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 363\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/c2-detection-TvTzD0kY-py3.10/lib/python3.10/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/c2-detection-TvTzD0kY-py3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:1058\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1056\u001b[0m     )\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m-> 1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m   1064\u001b[0m     _assert_all_finite(\n\u001b[1;32m   1065\u001b[0m         array,\n\u001b[1;32m   1066\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m   1067\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m   1068\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1069\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. LogisticRegression expected <= 2."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "with open(\"../../models/dridex/logreg.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Load encoders and scaler\n",
    "with open(\"../../variables/dridex/Protocol_Encoder.pkl\", \"rb\") as f:\n",
    "    protocol_encoder = pickle.load(f)\n",
    "\n",
    "with open(\"../../variables/dridex/Flags_Encoder.pkl\", \"rb\") as f:\n",
    "    flags_encoder = pickle.load(f)\n",
    "\n",
    "with open(\"../../variables/dridex/Direction_Encoder.pkl\", \"rb\") as f:\n",
    "    direction_encoder = pickle.load(f)\n",
    "\n",
    "with open(\"../../variables/dridex/scaler.pkl\", \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "# Paths to data folders\n",
    "folders = [\n",
    "    \"../../data/collected/normal_machines\",\n",
    "    \"../../data/collected/infected_machines\",\n",
    "]\n",
    "\n",
    "# Prediction threshold\n",
    "THRESHOLD = 0.5  # Since sigmoid activation is used\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "def process_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.loc[((df[\"Flags\"] == \"SYN,RST\") | (df[\"Flags\"] == \"RST,ACK\")), \"Flags\"] = (\n",
    "        \"RST\"\n",
    "    )\n",
    "    df.loc[((df[\"Protocol\"] == \"DATA-TEXT-LINES\")|(df[\"Protocol\"] == \"XML\")), \"Protocol\"] = \"MEDIA\"\n",
    "\n",
    "    df[\"Protocol\"] = protocol_encoder.transform(df[\"Protocol\"])\n",
    "    df[\"Flags\"] = flags_encoder.transform(df[\"Flags\"])\n",
    "    df[\"Direction\"] = direction_encoder.transform(df[\"Direction\"])\n",
    "\n",
    "    columns = df.columns\n",
    "    df = scaler.transform(df.to_numpy())\n",
    "    df = pd.DataFrame(df, columns=columns)\n",
    "    # Make predictions\n",
    "    predicted_labels = model.predict(df)\n",
    "\n",
    "\n",
    "    benign_count = np.sum(predicted_labels == 0)\n",
    "    dridex_count = np.sum(predicted_labels == 1)\n",
    "\n",
    "    # Determine file classification\n",
    "    file_status = \"Malicious\" if dridex_count > 0 else \"Benign\"\n",
    "\n",
    "    # Store results in a list\n",
    "    results.append(\n",
    "        {\n",
    "            \"File\": file_path,\n",
    "            \"Benign_Count\": benign_count,\n",
    "            \"Dridex_Count\": dridex_count,\n",
    "            \"Final_Classification\": file_status,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# Process all files in both folders\n",
    "for folder in folders:\n",
    "    for file_name in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, file_name)\n",
    "        process_file(file_path)\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save to CSV (optional)\n",
    "results_df.to_csv(\"classification_results.csv\", index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Benign_Count</th>\n",
       "      <th>Dridex_Count</th>\n",
       "      <th>Final_Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../data/collected/normal_machines/benign_3.csv</td>\n",
       "      <td>606</td>\n",
       "      <td>55</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../data/collected/normal_machines/benign_2.csv</td>\n",
       "      <td>572</td>\n",
       "      <td>52</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../data/collected/normal_machines/benign_5.csv</td>\n",
       "      <td>544</td>\n",
       "      <td>50</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../data/collected/normal_machines/benign_4.csv</td>\n",
       "      <td>481</td>\n",
       "      <td>40</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../data/collected/normal_machines/benign_1.csv</td>\n",
       "      <td>574</td>\n",
       "      <td>57</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>../../data/collected/infected_machines/infecte...</td>\n",
       "      <td>457</td>\n",
       "      <td>169</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>../../data/collected/infected_machines/infecte...</td>\n",
       "      <td>384</td>\n",
       "      <td>164</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>../../data/collected/infected_machines/infecte...</td>\n",
       "      <td>486</td>\n",
       "      <td>208</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>../../data/collected/infected_machines/infecte...</td>\n",
       "      <td>487</td>\n",
       "      <td>193</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>../../data/collected/infected_machines/infecte...</td>\n",
       "      <td>474</td>\n",
       "      <td>188</td>\n",
       "      <td>Malicious</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                File  Benign_Count  \\\n",
       "0  ../../data/collected/normal_machines/benign_3.csv           606   \n",
       "1  ../../data/collected/normal_machines/benign_2.csv           572   \n",
       "2  ../../data/collected/normal_machines/benign_5.csv           544   \n",
       "3  ../../data/collected/normal_machines/benign_4.csv           481   \n",
       "4  ../../data/collected/normal_machines/benign_1.csv           574   \n",
       "5  ../../data/collected/infected_machines/infecte...           457   \n",
       "6  ../../data/collected/infected_machines/infecte...           384   \n",
       "7  ../../data/collected/infected_machines/infecte...           486   \n",
       "8  ../../data/collected/infected_machines/infecte...           487   \n",
       "9  ../../data/collected/infected_machines/infecte...           474   \n",
       "\n",
       "   Dridex_Count Final_Classification  \n",
       "0            55            Malicious  \n",
       "1            52            Malicious  \n",
       "2            50            Malicious  \n",
       "3            40            Malicious  \n",
       "4            57            Malicious  \n",
       "5           169            Malicious  \n",
       "6           164            Malicious  \n",
       "7           208            Malicious  \n",
       "8           193            Malicious  \n",
       "9           188            Malicious  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    }
   ],
   "source": [
    "folders = [\n",
    "    \"../../data/collected/normal_machines\",\n",
    "]                         \n",
    "def process_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfc = df.copy()\n",
    "    df.loc[((df[\"Flags\"] == \"SYN,RST\") | (df[\"Flags\"] == \"RST,ACK\")), \"Flags\"] = \"RST\"\n",
    "    df.loc[\n",
    "        ((df[\"Protocol\"] == \"DATA-TEXT-LINES\") | (df[\"Protocol\"] == \"XML\")), \"Protocol\"\n",
    "    ] = \"MEDIA\"\n",
    "\n",
    "    df[\"Protocol\"] = protocol_encoder.transform(df[\"Protocol\"])\n",
    "    df[\"Flags\"] = flags_encoder.transform(df[\"Flags\"])\n",
    "    df[\"Direction\"] = direction_encoder.transform(df[\"Direction\"])\n",
    "\n",
    "    columns = df.columns\n",
    "    df = scaler.transform(df.to_numpy())\n",
    "    df = pd.DataFrame(df, columns=columns)\n",
    "    # Make predictions\n",
    "    X_lstm = np.expand_dims(df.values, axis=1)\n",
    "\n",
    "    predicted_labels = model.predict(X_lstm)\n",
    "    dfc[\"Label\"] = predicted_labels\n",
    "    dfc = dfc[dfc[\"Label\"] < 0.5]\n",
    "    dfc.drop(\"Label\", axis=1, inplace=True)\n",
    "    dfc.reset_index()\n",
    "    dfc.to_csv(f\"{file_path}\",index=False)\n",
    "\n",
    "\n",
    "# Process all files in both folders\n",
    "for folder in folders:\n",
    "    for file_name in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, file_name)\n",
    "        process_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c2-detection-TvTzD0kY-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
